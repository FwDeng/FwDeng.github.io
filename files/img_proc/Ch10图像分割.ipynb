{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第10章 图像分割\n",
    "\n",
    "- 图像分割（Image segmentation）是指将图像划分成若干个性质相似、互不相交的区域的过程，其本质是像素的分类或聚类，目的是简化或改变图像的表示形式，使得图像更容易理解和分析。\n",
    "- 图像分割依据像素灰度或颜色及其空间分布的基本特征—相似性、不连续性来完成，阈值分割、区域分裂与合并、运动目标分割等都是基于相似性的图像分割方法，例如把图像划分为灰度（亮度）、色彩、纹理或运动等属性大致相同的区域。不连续性体现为像素属性值空间分布的某种变化，往往对应于图像中属性不一致区域之间的过渡区域，如边缘、区域边界、纹理细节等，“第9章 边缘检测”就是此类图像分割的典型代表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入本章示例用到的包,使用本文档中示例,先运行一次本段代码\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from skimage import io,util,filters,feature,transform,\\\n",
    "                     draw,color,morphology,segmentation,measure\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 阈值分割\n",
    "- 如果前景物体或背景表面各自具有较为一致的光反射特性，且物体和背景之间、或不同物体之间表面的光反射特性差异较大，那么图像就会形成明暗不同的区域，只要选择一个合适的灰度值作为阈值，就可以根据像素灰度值的高低，把图像分割为前景区域和背景区域，关键是如何选择阈值。\n",
    "\n",
    "### 10.1.2 基本全局阈值图像分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例：基本全局阈值图像分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本全局阈值图像分割\n",
    "\n",
    "#读入一幅灰度图像\n",
    "img = io.imread('./imagedata/rice.png')\n",
    "#mg = data.camera()\n",
    "#将图像数据转换为浮点型\n",
    "imgf = np.float32(img)\n",
    "\n",
    "#初始化迭代次数\n",
    "count = 0;\n",
    "#选择迭代停止控制参数\n",
    "Delta_T =0.5\n",
    "#新阈值\n",
    "Thr_new = 0\n",
    "#用图像的灰度均值作为初始阈值\n",
    "Thr = np.mean(imgf)\n",
    "#迭代计算基本全局阈值\n",
    "done = True\n",
    "while done:\n",
    "    count = count + 1  #统计迭代次数\n",
    "    #计算两类像素的均值并更新阈值\n",
    "    Thr_new = 0.5*(np.mean(imgf[imgf>Thr]) + np.mean(imgf[imgf<=Thr]))\n",
    "    if np.abs(Thr - Thr_new) < Delta_T:\n",
    "        done = False\n",
    "    Thr = Thr_new\n",
    "    \n",
    "#用得到的阈值分割图像\n",
    "img_bw = img > Thr\n",
    "#显示阈值及迭代次数\n",
    "print('阈值=',Thr)\n",
    "print('迭代次数=',count)\n",
    "\n",
    "#显示图像阈值分割结果\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.gray()\n",
    "\n",
    "#输入图像\n",
    "plt.subplot(1,3,1), plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "#图像灰度直方图\n",
    "plt.subplot(1,3,2), plt.hist(img.ravel(), bins=256)\n",
    "plt.title('Histogram')\n",
    "plt.axvline(Thr, color='r')\n",
    "#二值图像\n",
    "plt.subplot(1,3,3), plt.imshow(img_bw)\n",
    "plt.title('Segment result')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1.3 Otsu最佳全局阈值图像分割\n",
    "\n",
    "- Otsu最佳阈值分割方法是由日本学者大津(Nobuyuki Otsu)于1979年提出的，又叫大津法。它根据图像灰度的统计特性，借助于灰度直方图，将图像分成目标和背景两类像素。Otsu定义了类间方差（variance between classes）的概念来衡量目标和背景两类像素之间的的可分性，如果目标和背景之间的类间方差越大，说明图像中这两部分像素的灰度值的差别越大。若部分目标被错分为背景，或部分背景被错分为目标，都会导致类间方差变小。因此，能够使类间方差最大的分割阈值意味着错分概率也最小。"
   ]
  },
  {
   "attachments": {
    "5e37091f-2002-4d8a-bf3b-82eac27ad10a.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例：Otsu单阈值分割\n",
    "\n",
    "![image.png](attachment:5e37091f-2002-4d8a-bf3b-82eac27ad10a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenCV 提供的函数\n",
    "- retval, dst = cv.threshold(src, thresh, maxval, type[, dst])\n",
    "    - Applies a fixed-level threshold to each array element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV: Otsu单阈值分割\n",
    "\n",
    "#读入一幅灰度图像\n",
    "img = cv.imread('./imagedata/rice.png', 0)\n",
    "\n",
    "#Otsu阈值分割\n",
    "thresh, imgbw1 = cv.threshold(img,127,255,cv.THRESH_OTSU | cv.THRESH_BINARY)\n",
    "thresh, imgbw2 = cv.threshold(img,127,255,cv.THRESH_OTSU | cv.THRESH_BINARY_INV)\n",
    "\n",
    "#显示Otsu阈值\n",
    "print('Otsu阈值 =',thresh)\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.gray()\n",
    "\n",
    "#原图像\n",
    "plt.subplot(1,4,1), plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "#图像灰度直方图\n",
    "plt.subplot(1,4,2), plt.hist(img.ravel(), bins=256)\n",
    "plt.title('Histogram')\n",
    "plt.axvline(thresh, color='r')\n",
    "#二值图像\n",
    "plt.subplot(1,4,3), plt.imshow(imgbw1 )\n",
    "plt.title('Otsu segmented result')\n",
    "plt.axis('off')\n",
    "#二值图像\n",
    "plt.subplot(1,4,4), plt.imshow(imgbw2)\n",
    "plt.title('Otsu segmented result')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-image 提供的函数\n",
    "- skimage.filters.threshold_otsu(image=None, nbins=256, *, hist=None)\n",
    "    - Return threshold value based on Otsu’s method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit-image: Otsu单阈值分割\n",
    "\n",
    "#读入一幅灰度图像\n",
    "img = io.imread('./imagedata/rice.png')\n",
    "\n",
    "#计算Otsu阈值\n",
    "thresh = filters.threshold_otsu(img)\n",
    "#对图像进行阈值分割\n",
    "img_binary = img > thresh\n",
    "\n",
    "#显示Otsu阈值\n",
    "print('Otsu阈值=',thresh)\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.gray()\n",
    "#输入图像\n",
    "plt.subplot(1,3,1), plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "#图像灰度直方图\n",
    "plt.subplot(1,3,2), plt.hist(img.ravel(), bins=256)\n",
    "plt.title('Histogram')\n",
    "plt.axvline(thresh, color='r')\n",
    "#二值图像\n",
    "plt.subplot(1,3,3), plt.imshow(img_binary )\n",
    "plt.title('Otsu segmented result')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "d958118d-5a33-4520-bed3-5d501174df7b.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例：Otsu多阈值分割（Multi-Otsu Thresholding）\n",
    "\n",
    "![image.png](attachment:d958118d-5a33-4520-bed3-5d501174df7b.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-image: Otsu多阈值分割\n",
    "\n",
    "#读入一幅灰度图像\n",
    "img = io.imread('./imagedata/cameraman.tif')\n",
    "\n",
    "#计算Otsu多阈值,选择默认classes=3,即计算2个阈值将图像分割为3类区域\n",
    "thresholds = filters.threshold_multiotsu(img, classes=3)\n",
    "#显示Otsu得到的2个阈值\n",
    "print('Otsu多阈值=',thresholds)\n",
    "\n",
    "# 使用阈值将图像分割成3类区域,取值分别为0,1,2\n",
    "img_regions = np.digitize(img, bins=thresholds)\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.gray()\n",
    "\n",
    "#输入图像\n",
    "plt.subplot(1,3,1); plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "#图像灰度直方图,叠加两个用multi-Otsu方法得到的阈值\n",
    "plt.subplot(1,3,2); plt.hist(img.ravel(), bins=256)\n",
    "plt.title('Histogram')\n",
    "for thresh in thresholds:\n",
    "    plt.axvline(thresh, color='r')\n",
    "#多阈值分割结果\n",
    "plt.subplot(1,3,3); plt.imshow(img_regions)\n",
    "plt.title('Multi-Otsu segmented result')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.4 自适应阈值图像分割\n",
    "\n",
    "- 噪声、非均匀光照都会影响图像全局阈值分割效果，严重时会导致分割失败。选择全局阈值时，主要依赖图像灰度直方图这一总体统计特征。\n",
    "- 局部均值和方差这两个统计量，描述了像素附近的对比度和明暗程度，体现了图像的不均匀性和局部灰度分布的特点，显然也可用来确定分割该像素的局部阈值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例：自适应阈值图像分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV 提供的函数\n",
    "- dst = cv.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C[, dst])\n",
    "    - Applies an adaptive threshold to an array. adaptiveMethod = cv.ADAPTIVE_THRESH_MEAN_C or cv.ADAPTIVE_THRESH_GAUSSIAN_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV: 自适应阈值图像分割Adaptive Thresholding\n",
    "\n",
    "#读入一幅灰度图像\n",
    "img = cv.imread('./imagedata/rice.png', 0)\n",
    "\n",
    "#Otsu全局阈值分割\n",
    "ret,binary_otsu = cv.threshold(img,127,255, cv.THRESH_OTSU | cv.THRESH_BINARY)\n",
    "#自适应阈值图像分割\n",
    "binary_localmean = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,blockSize=35,C=-15)\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.gray()\n",
    "#输入图像\n",
    "plt.subplot(1,3,1); plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "#Otsu全局阈值分割结果\n",
    "plt.subplot(1,3,2); plt.imshow(binary_otsu)\n",
    "plt.title('Otsu global thresholding')\n",
    "plt.axis('off')\n",
    "#local mean局部阈值分割结果\n",
    "plt.subplot(1,3,3); plt.imshow(binary_localmean)\n",
    "plt.title('local mean thresholding')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例：自适应阈值分割文本图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-image 提供的函数\n",
    "- skimage.filters.threshold_sauvola(image, window_size=15, k=0.2, r=None)\n",
    "    - Applies Sauvola local threshold to an array. Sauvola is a modification of Niblack technique.\n",
    "- skimage.filters.threshold_local(image, block_size, method='gaussian', offset=0, mode='reflect', param=None, cval=0)\n",
    "    - Compute a threshold mask image based on local pixel neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit-image: 自适应阈值分割文本图像\n",
    "\n",
    "#读入一幅文本灰度图像\n",
    "img = io.imread('./imagedata/page.png')\n",
    "\n",
    "#计算Otsu全局阈值\n",
    "thresh_otsu= filters.threshold_otsu(img)\n",
    "binary_otsu = img > thresh_otsu\n",
    "# Sauvola局部阈值\n",
    "thresh_sauvola = filters.threshold_sauvola(img, window_size=35)\n",
    "binary_sauvola = img > thresh_sauvola\n",
    "#Gaussian加权均值局部阈值\n",
    "thresh_gaussian = filters.threshold_local(img, block_size=35, method='gaussian',offset=5)\n",
    "binary_gaussian = img > thresh_gaussian\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.gray()\n",
    "\n",
    "#输入图像\n",
    "plt.subplot(2,2,1); plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "#Otsu全局阈值分割结果\n",
    "plt.subplot(2,2,2); plt.imshow(binary_otsu)\n",
    "plt.title('Otsu global thresholding')\n",
    "plt.axis('off')\n",
    "# Sauvola局部阈值分割结果\n",
    "plt.subplot(2,2,3); plt.imshow(binary_sauvola)\n",
    "plt.title('Sauvola local thresholding')\n",
    "plt.axis('off')\n",
    "# Gaussian加权局部阈值分割结果\n",
    "plt.subplot(2,2,4); plt.imshow(binary_gaussian)\n",
    "plt.title('Gaussian local thresholding')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV: 自适应阈值文本图像分割\n",
    "\n",
    "#读入一幅灰度图像\n",
    "img = cv.imread('./imagedata/page.png', 0)\n",
    "\n",
    "#全局Otsu阈值分割\n",
    "ret,img_otsu = cv.threshold(img,127,255, cv.THRESH_OTSU + cv.THRESH_BINARY)\n",
    "#自适应阈值图像分割\n",
    "img_adamean = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,cv.THRESH_BINARY,35,5)\n",
    "img_adagauss = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,35,5)\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.gray()\n",
    "\n",
    "#原图像\n",
    "plt.subplot(2,2,1); plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "#Otsu全局阈值分割结果\n",
    "plt.subplot(2,2,2); plt.imshow(img_otsu)\n",
    "plt.title('Otsu global thresholding')\n",
    "plt.axis('off')\n",
    "# ADAPTIVE_THRESH_MEAN_C分割结果\n",
    "plt.subplot(2,2,3); plt.imshow(img_adamean)\n",
    "plt.title('local mean thresholding')\n",
    "plt.axis('off')\n",
    "# ADAPTIVE_THRESH_GAUSSIAN_C加权局部阈值分割结果\n",
    "plt.subplot(2,2,4); plt.imshow(img_adagauss)\n",
    "plt.title('local Gaussian thresholding')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 区域生长 region growing\n",
    "- 区域生长（Region growing）根据预先定义的生长准则，将像素或子区域组合成更大区域的过程。区域生长先从需要分割的区域中找出一个或多个种子像素（种子点）作为生长的起始点，然后将与种子像素具有相同或相似性质的邻域像素，合并到种子像素所在的区域中。再将这些新添加像素作为新的种子像素，继续进行上述操作，直到没有满足生长准则的像素时，停止区域生长。\n",
    "- 区域生长算法的关键，一是确定相似性准则和区域生长的条件，二是停止规则的表示，三是种子像素的选取。相似性度量方法的选择不仅取决于所面对的问题，还取决于所处理图像的数据类型，如灰度图像、RGB真彩色图像等。下面以灰度图像为例，以候选像素灰度值与已生长区域像素灰度均值之差作为相似性度量方法，来说明区域生长算法的原理。\n",
    "\n",
    "\n",
    "### 定义区域生长函数region growing\n",
    "- #### 先运行函数定义cell装载函数，才能调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义区域生长函数region growing\n",
    "def regionGrow(grayimage, seeds, thresh, neighbors):\n",
    "    \"\"\"\n",
    "    输入参数:\n",
    "        grayimage - 灰度图像,ndarray\n",
    "            seeds - 种子点下标列表，形如:[(x0,y0),(x1,y1),...]\n",
    "           thresh - 阈值,浮点数,在[0,1]之间取值,用于度量衡量邻域像素灰度值与已生长区域的相似性。\n",
    "        neighbors - 采用的邻域类型，整数，4或8，对应4-邻域或8-邻域。\n",
    "    返回值：\n",
    "         seedMark - 二值图像,增长区域像素=255,其他=0\n",
    "    \"\"\"\n",
    "    #对输入图像做归一化处理[0,1]\n",
    "    gray = util.img_as_float(grayimage.copy())\n",
    "    #用于保存种子区域增长结果\n",
    "    seedMark = np.zeros(gray.shape).astype(np.uint8)\n",
    "    \n",
    "    #根据增长时的邻域类型确定邻域像素下标偏移量\n",
    "    if neighbors == 8:\n",
    "        #8-邻域,顺时针排列\n",
    "        connection = [(-1, -1), (-1, 0), (-1, 1), (0, 1),\n",
    "                      (1, 1), (1, 0), (1, -1), (0, -1)]\n",
    "    elif neighbors == 4:\n",
    "        #4-邻域,顺时针排列\n",
    "        connection = [(-1, 0), (0, 1), (1, 0), (0, -1)]\n",
    "    \n",
    "    #已增长的像素数\n",
    "    numpixels = 1.0\n",
    "    #已生长区域像素灰度均值\n",
    "    growed_region_mean =  gray[seeds[0][0],seeds[0][1]]\n",
    "    #已生长区域像素灰度值之和\n",
    "    growed_region_sum = growed_region_mean\n",
    "    \n",
    "    #seeds种子点列表内无元素时候生长停止\n",
    "    while len(seeds) != 0:\n",
    "        #种子点列表头部元素弹出\n",
    "        pt = seeds.pop(0)\n",
    "        for i in range(neighbors):\n",
    "            #遍历当前种子点邻域像素\n",
    "            tmpX = pt[0] + connection[i][0]\n",
    "            tmpY = pt[1] + connection[i][1]\n",
    "            #检测该邻域点是否位于图像内(下标是否有效)\n",
    "            if tmpX < 0 or tmpY < 0 or tmpX >= gray.shape[0] or tmpY >= gray.shape[1]:\n",
    "                continue\n",
    "            #判断是否满足相似性准则:\n",
    "            #该像素的灰度值和与已生长区域灰度均值之差的绝对值小于阈值thresh\n",
    "            gray_diff = abs(gray[tmpX, tmpY] - growed_region_mean)\n",
    "            if (gray_diff < thresh) and (seedMark[tmpX, tmpY] == 0):\n",
    "                #将当前像素在已生长区域的灰度值设为255\n",
    "                seedMark[tmpX, tmpY] = 255\n",
    "                #将当前像素添加到种子点列表\n",
    "                seeds.append((tmpX, tmpY))\n",
    "                \n",
    "                #更新已生长区域像素灰度值之和\n",
    "                growed_region_sum += gray[tmpX, tmpY]\n",
    "                #更新已增长的像素数\n",
    "                numpixels += 1\n",
    "                #更新已生长区域像素灰度均值\n",
    "                growed_region_mean = growed_region_sum/numpixels\n",
    "    \n",
    "    #返回结果\n",
    "    return seedMark\n",
    "#----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例：调用自定义区域增长函数regionGrow,分割图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用自定义区域增长函数regionGrow,分割图像\n",
    "\n",
    "#读入一幅灰度图像\n",
    "img = io.imread('./imagedata/medtest.png')\n",
    "\n",
    "#选择种子点\n",
    "seeds = [(125,250)]\n",
    "#区域增长\n",
    "seedMark1 = regionGrow(img, seeds, thresh=0.06, neighbors=8 )\n",
    "#选择种子点,改变分割阈值大小\n",
    "seeds = [(125,250)]\n",
    "#区域增长\n",
    "seedMark2 = regionGrow(img, seeds, thresh=0.2, neighbors=8 )\n",
    "\n",
    "#将分割区域叠加到原图像上\n",
    "img_res1 = img.copy()\n",
    "img_res1[seedMark1>0] = 255\n",
    "img_res2 = img.copy()\n",
    "img_res2[seedMark2>0] = 255\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.gray()\n",
    "#原图像\n",
    "plt.subplot(1,3,1); plt.imshow(img)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "#区域增长分割结果,叠加到按图像,thresh=0.06\n",
    "plt.subplot(1,3,2); plt.imshow(img_res1)\n",
    "plt.title('Region growing,thresh=0.06')\n",
    "plt.axis('off')\n",
    "# Niblack局部阈值分割结果,叠加到按图像,thresh=0.2\n",
    "plt.subplot(1,3,3); plt.imshow(img_res2)\n",
    "plt.title('Region growing,thresh=0.2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例：采用鼠标交互方式调用自定义区域增长函数regionGrow,分割图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采用鼠标交互方式调用自定义区域增长函数regionGrow,分割图像\n",
    "#在窗口显示的图像上双击鼠标左键,以鼠标点击位置为种子点\n",
    "# mouse callback function\n",
    "def Seg_regiongrow(event,x,y,flags,param):\n",
    "    global  img_gray, img_gray2\n",
    "    if event == cv.EVENT_LBUTTONDBLCLK:\n",
    "        #选择种子点\n",
    "        seeds = [(y,x)]\n",
    "        #区域增长\n",
    "        seedMark = regionGrow(img_gray, seeds, thresh=0.1, neighbors=8 )\n",
    "        #将分割区域叠加到原图像上\n",
    "        img_gray[seedMark>0] = 255\n",
    "    if event == cv.EVENT_RBUTTONDOWN:  # 单击右键从新开始选择\n",
    "        img_gray = img_gray2.copy()\n",
    "#---------------------------------- \n",
    "\n",
    "#主程序\n",
    "#读入一幅灰度图像\n",
    "img_gray = io.imread('./imagedata/medtest.png')\n",
    "img_gray2 = img_gray.copy()\n",
    "\n",
    "#创建显示窗口,绑定鼠标回调函数\n",
    "cv.namedWindow('image')\n",
    "cv.setMouseCallback('image',Seg_regiongrow)\n",
    "#循环执行直到按Esc键退出\n",
    "while(1):\n",
    "    cv.imshow('image',img_gray)\n",
    "    if cv.waitKey(20) & 0xFF == 27:  #按Esc键退出\n",
    "        break        \n",
    "        \n",
    "#释放占用资源\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {
    "1e165e52-618b-499c-8ca3-2a5984e0c396.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 分水岭图像分割 Watershed segmentation\n",
    "\n",
    "- 分水岭图像分割方法（Watershed segmentation）借用地形学概念，把图像类比为测地学上的拓扑地貌，图像中每一像素的灰度值表示该点的海拔高度，高灰度值像素代表山脉，低灰度值像素代表盆地。每一个局部极小值及其影响区域称为集水盆（catchment basin），集水盆周边的分水岭脊线形成分水线（watershed ridge line）。分水岭图像分割的目的，是找出图像中所有的集水盆区域及相应的分水线，因为这些集水盆区域通常对应于目标区域，分水线则对应于目标区域的轮廓线。\n",
    "\n",
    "- 分水线的形成可以通过模拟涨水淹没过程来说明。设想在地面每一个局部极小值位置（相当于洼地），刺穿一个小孔，让水通过小孔以均匀的速率上升，从低到高淹没整个地面。随着水位的上涨，对应每一个局部极小值的集水盆水面会慢慢向外扩展，当不同集水盆中的水面将要汇聚在一起时，在两个集水盆水面汇合处构筑大坝阻止水面汇合。这个过程不断延续直到水位上涨到最大值（对应于图像中灰度级的最大值），这些阻止各个集水盆水面交汇的大坝就是分水线。一旦确定出分水线的位置，就能将图像用一组封闭的曲线分割成不同的区域。\n",
    "\n",
    "![image.png](attachment:1e165e52-618b-499c-8ca3-2a5984e0c396.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例：二值图像中的目标分离―采用距离变换的分水岭图像分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-image分水岭图像分割\n",
    "- skimage.segmentation.watershed(image, markers=None, connectivity=1, offset=None, mask=None, compactness=0, watershed_line=False)\n",
    "- skimage.feature.peak_local_max(image, min_distance=1, threshold_abs=None, threshold_rel=None, exclude_border=True, indices=True, num_peaks=inf, footprint=None, labels=None, num_peaks_per_label=inf, p_norm=inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit-image: 采用距离变换的分水岭图像分割,将图中粘连的圆型区域分离开\n",
    "\n",
    "#读入一幅二值图像\n",
    "img = io.imread('./imagedata/circles.png')\n",
    "\n",
    "#对图像进行距离变换\n",
    "distance = cv.distanceTransform(img,cv.DIST_L2,5)\n",
    "\n",
    "#检出距离图像中的局部最大值作为标记\n",
    "#较小的footprint可能导致检出碎片区域局部最大值\n",
    "coords = feature.peak_local_max(distance.copy(),footprint=np.ones((7,7)),labels=img)\n",
    "\n",
    "#对局部最大值数组进行标记,即为每个局部最大值位置赋予唯一序号\n",
    "#创建标记数组\n",
    "maskers = np.zeros(distance.shape, dtype=bool)\n",
    "maskers[tuple(coords.T)] = True\n",
    "markers = measure.label(maskers)\n",
    "#对负距离图像进行基于标记的分水岭分割,得到图像中的连通区域已标记\n",
    "labels = segmentation.watershed(-distance, markers, mask=img, watershed_line=True)\n",
    "#对结果进行伪彩色处理\n",
    "labels_rgb = color.label2rgb(labels, bg_label=0,bg_color=(1,1,1))\n",
    "\n",
    "#显示连通区域数量\n",
    "print('区域数量：',np.max(labels))\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.gray()\n",
    "\n",
    "#输入图像,物体之间粘连重叠\n",
    "plt.subplot(1,4,1); plt.imshow(img)\n",
    "plt.title('Overlapping objects')\n",
    "plt.axis('off')\n",
    "#通过距离变换得到的距离图\n",
    "plt.subplot(1,4,2); plt.imshow(distance)\n",
    "plt.title('Distances')\n",
    "plt.axis('off')\n",
    "#对距离图取负\n",
    "plt.subplot(1,4,3); plt.imshow(- distance)\n",
    "plt.title('Negative Distances')\n",
    "plt.axis('off')\n",
    "#图像中的区域已分开,不同标号区域用不同彩色显示\n",
    "plt.subplot(1,4,4); plt.imshow(labels_rgb )\n",
    "plt.title('Separated objects')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV分水岭图像分割\n",
    "- markers=cv.watershed(image, markers)\n",
    "    - Performs a marker-based image segmentation using the watershed algorithm.\n",
    "- dst=cv.distanceTransform(src, distanceType, maskSize[, dst[, dstType]])\n",
    "    - Calculates the distance to the closest zero pixel for each pixel of the source image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV: 分水岭图像分割，将图中粘连的圆型区域分离开\n",
    "\n",
    "#读入一幅图像\n",
    "img = cv.imread('./imagedata/circles.png',0)\n",
    "#获取图像的高/宽\n",
    "rows, cols = img.shape[0:2]\n",
    "\n",
    "#将图像转换为彩色图像格式\n",
    "img_c = cv.cvtColor(img, cv.COLOR_GRAY2RGB)\n",
    "\n",
    "#采用OTSU阈值分割，得到二值图像\n",
    "ret, imgbw = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "\n",
    "#形态学滤波去除噪点\n",
    "#创建一个3×3的正方形结构元素\n",
    "kernel = cv.getStructuringElement(cv.MORPH_RECT,(3,3))\n",
    "img_opening = cv.morphologyEx(imgbw,cv.MORPH_OPEN,kernel, iterations = 1)\n",
    "\n",
    "#对结果进行膨胀\n",
    "sure_bg = cv.dilate(img_opening, kernel,iterations=2)\n",
    "#对图像进行距离变换\n",
    "dist_transform = cv.distanceTransform(img_opening,cv.DIST_L2,5)\n",
    "# 得到明确的前景区域\n",
    "ret, sure_fg = cv.threshold(dist_transform, 0.7*dist_transform.max(), 255,cv.THRESH_BINARY)\n",
    "#得到不明确区域 \n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv.subtract(sure_bg,sure_fg)\n",
    "\n",
    "#对明确的前景区域进行标记，得到分水岭算法所需的标记图像\n",
    "ret, markers = cv.connectedComponents(sure_fg)\n",
    "#将标记图像中不明确区域的像素值置为0\n",
    "markers[unknown==255] = 0\n",
    "markers2 = markers.copy()\n",
    "#对图像实施分水岭分割\n",
    "markers_seg = cv.watershed(img_c,markers2)\n",
    "\n",
    "#清除图像边界处的分水线\n",
    "markers_seg[0:rows,0] = 0\n",
    "markers_seg[0:rows,cols-1] = 0\n",
    "markers_seg[0,0:cols] = 0\n",
    "markers_seg[rows-1,0:cols] = 0\n",
    "#将分水线叠加到原图像上\n",
    "imgresult = img.copy()\n",
    "imgresult[markers_seg==-1] = 0\n",
    "\n",
    "#显示连通区域数量\n",
    "print('区域数量：',markers_seg.max())\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.gray()\n",
    "\n",
    "#原图像\n",
    "plt.subplot(2,3,1); plt.imshow(img)\n",
    "plt.title('Original image')\n",
    "plt.axis('off')\n",
    "#阈值分割得到的二值图像\n",
    "plt.subplot(2,3,2); plt.imshow(imgbw)\n",
    "plt.title('Segmented image')\n",
    "plt.axis('off')\n",
    "#通过距离变换得到的距离图\n",
    "plt.subplot(2,3,3); plt.imshow(dist_transform)\n",
    "plt.title('Distances')\n",
    "plt.axis('off')\n",
    "#对距离图取阈值，得到待分割区域的标记区域 \n",
    "plt.subplot(2,3,4); plt.imshow(sure_fg)\n",
    "plt.title('sure foreground area')\n",
    "plt.axis('off')\n",
    "\n",
    "#标记图像\n",
    "plt.subplot(2,3,5); plt.imshow(markers,cmap='RdPu')\n",
    "plt.title('markers')\n",
    "plt.axis('off')\n",
    "#图像中的区域已分开,不同标号区域用不同彩色显示\n",
    "plt.subplot(2,3,6); plt.imshow(imgresult)\n",
    "plt.title('Separated objects')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#io.imsave('circles_labels_color.png',util.img_as_ubyte(labels_rgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例：结合边缘检测的分水岭图像分割\n",
    "- Make segmentation using edge-detection and watershed\n",
    " -  Scikit-image 版本>0.20.0时，markers数据类型改为 int型\n",
    " - segmentation.watershed(edges, markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit-image: 结合边缘检测的分水岭图像分割\n",
    "# Make segmentation using edge-detection and watershed.\n",
    "#读入一幅灰度图像\n",
    "img = io.imread('./imagedata/coins.png')\n",
    "\n",
    "#边缘检测\n",
    "#edges = filters.sobel(img)\n",
    "#使用 Canny 边缘检测\n",
    "edges = feature.canny(img) #Scikit-image: Canny 算子,采用缺省参数\n",
    "\n",
    "#对图像做阈值分割，得到部分前景和背景像素作为分水岭的种子标记\n",
    "# Scikit-image 版本>0.20.0时，markers数据类型改为 int型\n",
    "markers = np.zeros(img.shape, dtype = int)\n",
    "foreground = 1\n",
    "background = 2\n",
    "markers[img < 30] = background\n",
    "markers[img > 150] = foreground\n",
    "\n",
    "#也可采用OpenCV函数实现分割\n",
    "#将图像转换为彩色图像格式\n",
    "#edges_c = cv.cvtColor(edges.astype(np.uint8), cv.COLOR_GRAY2RGB)\n",
    "#对边缘图像做分水岭分割\n",
    "#imws = cv.watershed(edges_c, markers)\n",
    "\n",
    "imws = segmentation.watershed(edges, markers)\n",
    "#得到对应的二值图像\n",
    "imbw = (imws==foreground)\n",
    "#对图像做形态学开运算\n",
    "imbw = morphology.binary_opening(imbw,morphology.disk(3))\n",
    "#对二值图像中的连通区域进行标记\n",
    "img_label = measure.label(imbw)\n",
    "#对标记图像作伪彩色处理,并叠加到原图像上\n",
    "img_color = color.label2rgb(img_label, image=img, bg_label=0)\n",
    "\n",
    "# 显示分割结果\n",
    "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(16, 8))\n",
    "ax = axes.ravel()\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "#硬币图像\n",
    "ax[0].imshow(img, cmap='gray')\n",
    "ax[0].set_title('Image')\n",
    "#Canny边缘\n",
    "ax[1].imshow(edges, cmap='gray')\n",
    "ax[1].set_title('Canny edges')\n",
    "#分水岭分割得到的二值图像\n",
    "ax[2].imshow(imbw, cmap='gray')\n",
    "ax[2].set_title('Canny+Watershed segmented Image')\n",
    "#分割区域伪彩色处理结果\n",
    "ax[3].imshow(img_color)\n",
    "ax[3].set_title('Pseudo-color labeled image')\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 彩色图像分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 鼠标选取感兴趣区域（ROI）画不规则多边形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 鼠标选取感兴趣区域（ROI）画不规则多边形\n",
    "# -----------------------鼠标操作相关------------------------\n",
    "#在显示的图像上单击鼠标左键选点,双击左键确认结束,单击右键从新开始\n",
    "#按任意键退出程序\n",
    "PointsChosen = [] #保存鼠标左键选取的像素坐标(x,y),元组列表list\n",
    "\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global img\n",
    "    global PointsChosen  # 存入选择的点\n",
    "    global img2\n",
    "    img2 = img.copy()  # 重新在原图上画出点及连线\n",
    "     \n",
    "    if event == cv.EVENT_LBUTTONDOWN:  #单击左键选点\n",
    "        #将选取的点保存到list列表里\n",
    "        PointsChosen.append((x, y))\n",
    "        #绿色圆环画出鼠标点击的像素\n",
    "        cv.circle(img2, (x, y), 5, (0, 255, 0), 2)\n",
    "        #将鼠标选的点用红色直线连起来\n",
    "        for i in range(len(PointsChosen) - 1):\n",
    "            cv.line(img2, PointsChosen[i], PointsChosen[i + 1], (0, 0, 255), 2)        \n",
    "        #显示绘图\n",
    "        cv.imshow('src', img2)\n",
    "        \n",
    "    if event == cv.EVENT_LBUTTONDBLCLK: #双击左键确认结束,得到ROI mask\n",
    "        ROImask_byMouse()\n",
    "        #PointsChosen = []  \n",
    "        \n",
    "    if event == cv.EVENT_RBUTTONDOWN:  # 单击右键从新开始选择\n",
    "        PointsChosen = []\n",
    "        cv.imshow('src', img2)\n",
    "        \n",
    "# ----得到选取的多边形顶点,得到ROI掩膜图像并做其他处理-------------\n",
    "\n",
    "def ROImask_byMouse():\n",
    "    global ROImask\n",
    "    ROImask = np.zeros(img.shape, np.uint8)\n",
    "    pts = np.array(PointsChosen, np.int32)  # pts是多边形的顶点列表（顶点集）\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    # 这里 reshape 的第一个参数为-1, 表明这一维的长度是根据后面的维度的计算出来的。\n",
    "    # OpenCV中需要先将多边形的顶点坐标变成顶点数×1×2维的矩阵，再来绘制\n",
    "    \n",
    "    #---填充多边形---\n",
    "    ROImask = cv.fillPoly(ROImask, [pts], (255, 255, 255))\n",
    "    cv.imshow('mask', ROImask)\n",
    "    ROI = cv.bitwise_and(ROImask, img)\n",
    "    cv.imshow('ROI', ROI)\n",
    "\n",
    "#-----读取一幅图像,用鼠标选择ROI----------\n",
    "img = cv.imread('./imagedata/Bridewedding.jpeg')\n",
    "\n",
    "cv.namedWindow('src')\n",
    "cv.setMouseCallback('src', on_mouse)\n",
    "cv.imshow('src', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度揭秘—蓝幕抠图技术的实现\n",
    "\n",
    "### 指定样本区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定样本区域\n",
    "#读取一幅彩色图像\n",
    "imgc = io.imread('./imagedata/Bridewedding.jpeg')\n",
    "\n",
    "#采用棋盘格距离Chebyshev disctance\n",
    "#分割阈值RGB \n",
    "Thresh = np.array([50,50,90])\n",
    "#指定样本掩膜\n",
    "sampling_mask = np.zeros(imgc.shape[0:2])\n",
    "sampling_mask[20:100,20:50] = 255\n",
    "\n",
    "#计算样本像素RGB颜色分量的平均值\n",
    "bg_mean = np.mean(imgc[sampling_mask>0],axis=0).astype((np.float))\n",
    "#确定属于背景的像素,即在RGB颜色空间中判断每个像素的RGB值,\n",
    "#是否落在以样本均值为中心,2*Thresh为边长的矩形空间内\n",
    "bgmask = np.abs(imgc.astype(np.float) - bg_mean)< Thresh\n",
    "bgmask = np.all(bgmask,axis=2)\n",
    "\n",
    "#抠图,令背景颜色等于指定值[r,g,b]\n",
    "img_res = imgc.copy()\n",
    "img_res[bgmask>0]= [125,125,125]\n",
    "\n",
    "#显示结果\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.gray()\n",
    "\n",
    "#输入图像\n",
    "plt.subplot(1,3,1), plt.imshow(imgc)\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "#背景掩膜\n",
    "plt.subplot(1,3,2), plt.imshow(bgmask)\n",
    "plt.title('Background mask')\n",
    "plt.axis('off')\n",
    "#抠图结果\n",
    "plt.subplot(1,3,3), plt.imshow(img_res)\n",
    "plt.title('Image matting ')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用鼠标交互选背景样本像素区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 蓝幕抠图技术的实现--用鼠标交互选背景样本像素区域\n",
    "\n",
    "# -----------------------鼠标操作相关------------------------\n",
    "#在显示的图像上单击鼠标左键选点,双击左键确认结束,单击右键从新开始\n",
    "#按任意键退出程序\n",
    "PointsChosen = [] #保存鼠标左键选取的像素坐标(x,y),元组列表list\n",
    "# 定义鼠标事件回调函数mouse callback function\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global img\n",
    "    global PointsChosen  # 存入选择的点\n",
    "    global img2\n",
    "    img2 = img.copy()  # 重新在原图上画出点及连线\n",
    "     \n",
    "    if event == cv.EVENT_LBUTTONDOWN:  #单击左键选点\n",
    "        #将选取的点保存到list列表里\n",
    "        PointsChosen.append((x, y))\n",
    "        #绿色圆环画出鼠标点击的像素\n",
    "        cv.circle(img2, (x, y), 5, (0, 255, 0), 2)\n",
    "        #将鼠标选的点用红色直线连起来\n",
    "        for i in range(len(PointsChosen) - 1):\n",
    "            cv.line(img2, PointsChosen[i], PointsChosen[i + 1], (255, 0, 0), 2)        \n",
    "        #显示绘图\n",
    "        cv.imshow('Image matting', img2[:,:,::-1])\n",
    "        \n",
    "    if event == cv.EVENT_LBUTTONDBLCLK: #双击左键确认结束,得到ROI mask\n",
    "        #调用抠图函数\n",
    "        image_matting_samplingbyMouse()         \n",
    "        \n",
    "    if event == cv.EVENT_RBUTTONDOWN:  # 单击右键从新开始选择\n",
    "        PointsChosen = []\n",
    "        cv.imshow('Image matting', img2[:,:,::-1])\n",
    "#----------------------------------------------------\n",
    "\n",
    "# ----用选取的多边形顶点,得到ROI掩膜图像并做其他处理-------------\n",
    "\n",
    "def image_matting_samplingbyMouse():\n",
    "    global sampling_mask, img, img2, PointsChosen,shift\n",
    "    #样本像素掩膜\n",
    "    sampling_mask =  np.zeros(img.shape[0:2])\n",
    "    \n",
    "    pts = np.array(PointsChosen, np.int32)  # pts是多边形的顶点列表（顶点集）\n",
    "    #---填充多边形---\n",
    "    sampling_mask = cv.fillPoly(sampling_mask, [pts], (255, 255, 255))\n",
    "    \n",
    "    #计算样本像素RGB颜色分量的平均值\n",
    "    bg_mean = np.mean(img[sampling_mask>0],axis=0).astype((np.float))\n",
    "    #确定属于背景的像素,即在RGB颜色空间中判断每个像素的RGB值,\n",
    "    #是否落在以样本均值为中心,2*Thresh为边长的矩形空间内\n",
    "    bgmask = np.abs(img.astype(np.float) - bg_mean)< Thresh\n",
    "    bgmask = np.all(bgmask,axis=2)\n",
    "\n",
    "    #抠图,令背景颜色等于指定值[r,g,b]\n",
    "    img2[bgmask>0]= [125,125,125]\n",
    "    \n",
    "    #清空顶点列表\n",
    "    PointsChosen = []\n",
    "    #显示最终结果\n",
    "    cv.imshow('Image matting',img2[:,:,::-1])\n",
    "#----------------------------------------------------\n",
    "\n",
    "#主程序    \n",
    "#-----读取一幅图像,用鼠标选择ROI----------\n",
    "#读取一幅彩色图像\n",
    "img = io.imread('./imagedata/Bridewedding.jpeg')\n",
    "\n",
    "#RGB分割阈值\n",
    "Thresh = np.array([50,50,90])\n",
    "\n",
    "cv.namedWindow('Image matting')\n",
    "cv.setMouseCallback('Image matting', on_mouse)\n",
    "cv.imshow('Image matting', img[:,:,::-1])\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 运动目标分割\n",
    "\n",
    "- 运动目标分割（Moving object segmentation），又称运动目标检测（Moving object detection），或运动分割（Motion segmentation），利用运动信息获取图像中移动目标区域，广泛应用于智能视频监控、视频压缩编码、视频检索、人机交互、虚拟现实、机器人视觉、自主导航等领域。在成像过程中，摄像机自身还是场景中物体的运动，都会使图像传感器与被观察目标之间产生相对位移，表现为序列图像中像素与场景物点的映射关系发生改变，引起图像像素属性值的变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 示例：摄像机固定配置时的视频运动目标分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 采用参考图像帧背景减除法实现视频图像运动目标检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采用参考图像帧背景减除法实现视频图像运动目标检测\n",
    "#创建指定视频文件读取对象\n",
    "videocap = cv.VideoCapture('./imagedata/vtest.avi')\n",
    "\n",
    "#检查是否正确打开视频文件\n",
    "if videocap.isOpened(): \n",
    "    oepn, frame = videocap.read()\n",
    "    # 获取视频fps\n",
    "    fps = videocap.get(cv.CAP_PROP_FPS)\n",
    "    delay = int(1000/fps)\n",
    "else:\n",
    "    open = False\n",
    "\n",
    "#指定分割阈值\n",
    "Thresh =25\n",
    "#读取视频序列中第一帧作为参考背景 \n",
    "ret, bgframe = videocap.read()\n",
    "\n",
    "#逐帧显示并处理    \n",
    "while open:\n",
    "    ret, frame = videocap.read() #读取一帧图像\n",
    "    #if frame is None: #已处理完最后一帧,退出循环\n",
    "    #   break\n",
    "    if not ret:  #已处理完最后一帧，退出循环\n",
    "        print(\"Can't receive frame! Exiting ...\")\n",
    "        break    \n",
    "\n",
    "    #计算每帧图像个颜色通道与参考帧之间的差值\n",
    "    framediff = bgframe.astype(np.float) - frame.astype(np.float)\n",
    "    fgmask = np.any(np.abs(framediff)> Thresh, axis=2)\n",
    "    fgmask = util.img_as_ubyte(fgmask) \n",
    "     \n",
    "    #显示结果\n",
    "    cv.namedWindow('video playing',cv.WINDOW_NORMAL)\n",
    "    cv.namedWindow('Segmented result',cv.WINDOW_NORMAL)\n",
    "    cv.imshow('video playing', frame) \n",
    "    cv.imshow('Segmented result',fgmask)\n",
    "        \n",
    "    if cv.waitKey(delay) & 0xFF == 27: #按帧率播放\n",
    "        break\n",
    "\n",
    "#释放视频读取资源\n",
    "videocap.release()\n",
    "#释放窗口显示资源\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.采用近似中值滤波背景模型实现运动目标分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采用近似中值滤波背景模型实现运动目标分割\n",
    "#Approximate Median Filter background model\n",
    "#创建指定视频文件读取对象\n",
    "videocap = cv.VideoCapture('./imagedata/vtest.avi')\n",
    "\n",
    "#检查是否正确打开视频文件\n",
    "if videocap.isOpened(): \n",
    "    oepn, frame = videocap.read()\n",
    "    # 获取视频fps\n",
    "    fps = videocap.get(cv.CAP_PROP_FPS)\n",
    "    delay = int(1000/fps)\n",
    "else:\n",
    "    open = False\n",
    "\n",
    "#指初始化阈值和更新增量beta\n",
    "Thresh =20\n",
    "Beta = 1.0\n",
    "\n",
    "#读取视频序列中第一帧作为参考背景 \n",
    "ret, bgframe = videocap.read()\n",
    "bgframe = np.float32(bgframe)\n",
    "\n",
    "#逐帧显示并处理    \n",
    "while open:\n",
    "    ret, frame = videocap.read() #读取一帧图像\n",
    "    if frame is None:  #已处理完最后一帧,退出循环\n",
    "        break\n",
    "   \n",
    "    #计算每帧图像个颜色通道与参考帧之间的差值\n",
    "    framediff = bgframe.astype(np.int) - frame.astype(np.int)\n",
    "    #更新背景模型 Update the median of each pixel value\n",
    "    decidx = framediff>0\n",
    "    incidx = framediff<0\n",
    "    bgframe[decidx] = bgframe[decidx] - Beta\n",
    "    bgframe[incidx] = bgframe[incidx] + Beta\n",
    "    #计算差值并取绝对值\n",
    "    fgmask = np.any(np.abs(framediff)> Thresh, axis=2)\n",
    "    fgmask = util.img_as_ubyte(fgmask)\n",
    "       \n",
    "    #显示结果\n",
    "    cv.namedWindow('video playing',cv.WINDOW_NORMAL)\n",
    "    cv.namedWindow('Segmented result',cv.WINDOW_NORMAL)\n",
    "    cv.imshow('video playing', frame) \n",
    "    cv.imshow('Segmented result',fgmask)\n",
    "        \n",
    "    if cv.waitKey(delay) & 0xFF == 27: #按帧率播放\n",
    "        break\n",
    "\n",
    "#释放视频读取资源\n",
    "videocap.release()\n",
    "#释放窗口显示资源\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 运动目标分割-采用OpenCV的MoG2背景模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#采用OpenCV的MoG2背景模型的运动目标分割\n",
    "#创建指定视频文件读取对象\n",
    "videocap = cv.VideoCapture('./imagedata/vtest.avi')\n",
    "\n",
    "#创建MoG背景模型对象\n",
    "motionsegmog = cv.createBackgroundSubtractorMOG2()\n",
    "\n",
    "#检查是否正确打开视频文件\n",
    "if videocap.isOpened(): \n",
    "    oepn, frame = videocap.read()\n",
    "    # 获取视频fps\n",
    "    fps = videocap.get(cv.CAP_PROP_FPS)\n",
    "    delay = int(1000/fps)\n",
    "else:\n",
    "    open = False\n",
    "    \n",
    "#cv.namedWindow('video playing',cv.WINDOW_NORMAL)\n",
    "#cv.namedWindow('Segmented result',cv.WINDOW_NORMAL)\n",
    "#逐帧显示并处理\n",
    "while open:\n",
    "    ret, frame = videocap.read() #读取一帧图像\n",
    "    #if frame is None:  #已处理完最后一帧,退出循环\n",
    "    #    break\n",
    "    if not ret:  #已处理完最后一帧，退出循环\n",
    "        print(\"Can't receive frame! Exiting ...\")\n",
    "        break\n",
    "    #运动分割\n",
    "    fgmask = motionsegmog.apply(frame)    \n",
    "   \n",
    "    #显示结果\n",
    "    cv.imshow('video playing', frame) \n",
    "    cv.imshow('Segmented result',fgmask)\n",
    "        \n",
    "    if cv.waitKey(delay) & 0xFF == 27: #按帧率播放\n",
    "        break\n",
    "        \n",
    "#释放视频读取资源\n",
    "videocap.release()\n",
    "#释放窗口显示资源\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【彩蛋系列】 之 基于深度学习的人脸检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV: 基于深度学习的人脸检测\n",
    "\n",
    "#读入一幅图像\n",
    "img = cv.imread('./imagedata/Bridewedding.jpeg')\n",
    "#获取图像的高和宽，用于画图\n",
    "h, w =img.shape[:2] \n",
    "\n",
    "#DNN网络输入图像的大小尺寸\n",
    "inWidth = 300; inHeight = 300\n",
    "confThreshold = 0.15 # 置信度参数,高于此数才认为是人脸,可调\n",
    "#导入DNN模块\n",
    "net = cv.dnn.readNetFromCaffe('./OpenCVData/deploy.prototxt', './OpenCVData/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "\n",
    "# 输入图片并重置大小符合模型的输入要求\n",
    "blob = cv.dnn.blobFromImage(img, 1.0, (inWidth, inHeight), [104., 117., 123.], swapRB=False,crop=False)\n",
    "net.setInput(blob)\n",
    "#DNN网络推理预测\n",
    "detections = net.forward()\n",
    "\n",
    "#结果可视化,在原图加上标签和框\n",
    "for i in range(0, detections.shape[2]):\n",
    "    #获得置信度\n",
    "    res_confidence = detections[0, 0, i, 2]\n",
    "    # 过滤掉低置信度的像素\n",
    "    if res_confidence > confThreshold :\n",
    "        #获得框的位置\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        # 在图片上写上标签\n",
    "        text = \"{:.2f}%\".format(res_confidence * 100)\n",
    "        #如果检测脸部在左上角，则把标签放在图片内，否则放在图片上面\n",
    "        y = startY - 10 if startY - 10 > 10 else startY + 10 \n",
    "        #绘制人脸区域的包围盒及标签      \n",
    "        img = cv.rectangle(img, (startX, startY), (endX, endY),(0, 255, 0), 2)\n",
    "        img = cv.putText(img, text, (startX, y), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 0), 2)\n",
    "        \n",
    "#创建窗口，显示结果\n",
    "plt.figure(figsize=(12,6)) \n",
    "\n",
    "plt.imshow(img[:,:,::-1])\n",
    "plt.title('Face detection using OpenCV DNN Caffe')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【彩蛋系列】 之 行人检测 Pedestrian detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedestrian detection using OpenCV DNN module and YOLO V4\n",
    "# load the COCO class labels:\n",
    "class_names = open(\"./OpenCVData/coco.names\").read().strip().split(\"\\n\")\n",
    "\n",
    "# Load the serialized caffe model from disk:\n",
    "net = cv.dnn.readNetFromDarknet(\"./OpenCVData/yolov4.cfg\", \"./OpenCVData/yolov4.weights\")\n",
    "\n",
    "# Load input image:\n",
    "image = cv.imread(\"./imagedata/Bridewedding.jpeg\")\n",
    "H, W = image.shape[:2]\n",
    "\n",
    "# Get the output layer names:\n",
    "layer_names = net.getLayerNames()\n",
    "\n",
    "layer_names = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "#若高版本OpenCV此语句出错，请改为下语句\n",
    "#layer_names = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# Create the blob with a size of (416, 416), swap red and blue channels\n",
    "# and also a scale factor of 1/255 = 0,003921568627451:\n",
    "blob = cv.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "\n",
    "# Feed the input blob to the network, perform inference and get the output:\n",
    "net.setInput(blob)\n",
    "layerOutputs = net.forward(layer_names)\n",
    "\n",
    "# Get inference time:\n",
    "t, _ = net.getPerfProfile()\n",
    "print('Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency()))\n",
    "\n",
    "# Initialization:\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "# loop over each of the layer outputs\n",
    "for output in layerOutputs:\n",
    "    # loop over each of the detections\n",
    "    for detection in output:\n",
    "        # Get class ID and confidence of the current detection:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "\n",
    "        # Filter out weak predictions:\n",
    "        if class_id==0 and confidence > 0.25:\n",
    "            # Scale the bounding box coordinates (center, width, height) using the dimensions of the original image:\n",
    "            box = detection[0:4] * np.array([W, H, W, H])\n",
    "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "            # Calculate the top-left corner of the bounding box:\n",
    "            x = int(centerX - (width / 2))\n",
    "            y = int(centerY - (height / 2))\n",
    "\n",
    "            # Update the information we have for each detection:\n",
    "            boxes.append([x, y, int(width), int(height)])\n",
    "            confidences.append(float(confidence))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "# We can apply non-maxima suppression (eliminate weak and overlapping bounding boxes):\n",
    "indices = cv.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "\n",
    "# Show the results (if any object is detected after non-maxima suppression):\n",
    "if len(indices) > 0:\n",
    "    for i in indices.flatten():\n",
    "        # Extract the (previously recalculated) bounding box coordinates:\n",
    "        (x, y) = (boxes[i][0], boxes[i][1])\n",
    "        (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "        # Draw label and confidence:\n",
    "        cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        label = \"{}: {:.4f}\".format(class_names[class_ids[i]], confidences[i])\n",
    "        labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "        y = max(y, labelSize[1])\n",
    "        cv.rectangle(image, (x, y - labelSize[1]), (x + labelSize[0], y + 0), (0, 255, 0), cv.FILLED)\n",
    "        cv.putText(image, label, (x, y), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "#创建窗口，显示结果\n",
    "plt.figure(figsize=(12,6)) \n",
    "\n",
    "plt.imshow(image[:,:,::-1])\n",
    "plt.title('Pedestrian detection using OpenCV DNN module and YOLO V4')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【彩蛋系列】 之 物体检测OpenCV deep learning object detection\n",
    "### MobileNet-SSD for object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object detection using OpenCV DNN module using MobileNet-SSD and caffe pre-trained models\n",
    "# Load input image:\n",
    "image = cv.imread(\"./imagedata/object_detection_test_image.png\")\n",
    "# Load the serialized caffe model from disk:\n",
    "net = cv.dnn.readNetFromCaffe(\"./OpenCVData/MobileNetSSD_deploy.prototxt\", \"./OpenCVData/MobileNetSSD_deploy.caffemodel\")\n",
    "\n",
    "# Prepare labels of the network (20 class labels + background):\n",
    "class_names = {0: 'background', 1: 'aeroplane', 2: 'bicycle', 3: 'bird', 4: 'boat', 5: 'bottle', 6: 'bus', 7: 'car',\n",
    "               8: 'cat', 9: 'chair', 10: 'cow', 11: 'diningtable', 12: 'dog', 13: 'horse', 14: 'motorbike',\n",
    "               15: 'person', 16: 'pottedplant', 17: 'sheep', 18: 'sofa', 19: 'train', 20: 'tvmonitor'}\n",
    "\n",
    "# Create the blob with a size of (300,300), mean subtraction values (127.5, 127.5, 127.5):\n",
    "# and also a scalefactor of 0.007843:\n",
    "blob = cv.dnn.blobFromImage(image, 0.007843, (300, 300), (127.5, 127.5, 127.5))\n",
    "print(blob.shape)\n",
    "\n",
    "# Feed the input blob to the network, perform inference and ghe the output:\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "\n",
    "# Get inference time:\n",
    "t, _ = net.getPerfProfile()\n",
    "print('Inference time: %.2f ms' % (t * 1000.0 / cv.getTickFrequency()))\n",
    "\n",
    "# Size of frame resize (300x300)\n",
    "dim = 300\n",
    "\n",
    "# Process all detections:\n",
    "for i in range(detections.shape[2]):\n",
    "    # Get the confidence of the prediction:\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    # Filter predictions by confidence:\n",
    "    if confidence > 0.25:\n",
    "        # Get the class label:\n",
    "        class_id = int(detections[0, 0, i, 1])\n",
    "\n",
    "        # Get the coordinates of the object location:\n",
    "        xLeftBottom = int(detections[0, 0, i, 3] * dim)\n",
    "        yLeftBottom = int(detections[0, 0, i, 4] * dim)\n",
    "        xRightTop = int(detections[0, 0, i, 5] * dim)\n",
    "        yRightTop = int(detections[0, 0, i, 6] * dim)\n",
    "\n",
    "        # Factor for scale to original size of frame\n",
    "        heightFactor = image.shape[0] / dim\n",
    "        widthFactor = image.shape[1] / dim\n",
    "\n",
    "        # Scale object detection to frame\n",
    "        xLeftBottom = int(widthFactor * xLeftBottom)\n",
    "        yLeftBottom = int(heightFactor * yLeftBottom)\n",
    "        xRightTop = int(widthFactor * xRightTop)\n",
    "        yRightTop = int(heightFactor * yRightTop)\n",
    "\n",
    "        # Draw rectangle:\n",
    "        cv.rectangle(image, (xLeftBottom, yLeftBottom), (xRightTop, yRightTop), (0, 255, 0), 2)\n",
    "\n",
    "        # Draw label and confidence:\n",
    "        if class_id in class_names:\n",
    "            label = class_names[class_id] + \": \" + str(confidence)\n",
    "            labelSize, baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "            yLeftBottom = max(yLeftBottom, labelSize[1])\n",
    "            cv.rectangle(image, (xLeftBottom, yLeftBottom - labelSize[1]),\n",
    "                          (xLeftBottom + labelSize[0], yLeftBottom + 0), (0, 255, 0), cv.FILLED)\n",
    "            cv.putText(image, label, (xLeftBottom, yLeftBottom), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "#物体检测结果\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(image[:,:,::-1])\n",
    "plt.title('Detection result')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
